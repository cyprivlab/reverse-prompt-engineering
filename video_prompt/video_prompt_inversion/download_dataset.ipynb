{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00fd74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cambrian from ./checkpoints/LongVU_Llama3_2_3B\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './checkpoints/LongVU_Llama3_2_3B'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/longvu/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/longvu/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/longvu/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './checkpoints/LongVU_Llama3_2_3B'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlongvu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmm_datautils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     KeywordsStoppingCriteria,\n\u001b[1;32m     11\u001b[0m     process_images,\n\u001b[1;32m     12\u001b[0m     tokenizer_image_token,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdecord\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cpu, VideoReader\n\u001b[0;32m---> 16\u001b[0m tokenizer, model, image_processor, context_len \u001b[38;5;241m=\u001b[39m \u001b[43mload_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./checkpoints/LongVU_Llama3_2_3B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcambrian_llama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mload_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     21\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./examples/video2.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/LongVU/longvu/builder.py:164\u001b[0m, in \u001b[0;36mload_pretrained_model\u001b[0;34m(model_path, model_base, model_name, load_8bit, load_4bit, device_map, device, use_flash_attn, model_args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Cambrian from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m             tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m             model \u001b[38;5;241m=\u001b[39m CambrianLlamaForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    166\u001b[0m                 model_path, low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    167\u001b[0m             )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Load language model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:826\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    825\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 826\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    828\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:658\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    657\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 658\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/utils/hub.py:466\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: './checkpoints/LongVU_Llama3_2_3B'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from longvu.builder import load_pretrained_model\n",
    "from longvu.constants import (\n",
    "    DEFAULT_IMAGE_TOKEN,\n",
    "    IMAGE_TOKEN_INDEX,\n",
    ")\n",
    "from longvu.conversation import conv_templates, SeparatorStyle\n",
    "from longvu.mm_datautils import (\n",
    "    KeywordsStoppingCriteria,\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    ")\n",
    "from decord import cpu, VideoReader\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    \"./checkpoints/LongVU_Llama3_2_3B\", None, \"cambrian_llama\",load_8bit=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "video_path = \"./examples/video2.mp4\"\n",
    "qs = \"What's the prompt to generate the video?\"\n",
    "\n",
    "vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
    "fps = float(vr.get_avg_fps())\n",
    "frame_indices = np.array([i for i in range(0, len(vr), round(fps),)])\n",
    "video = []\n",
    "for frame_index in frame_indices:\n",
    "    img = vr[frame_index].asnumpy()\n",
    "    video.append(img)\n",
    "video = np.stack(video)\n",
    "image_sizes = [video[0].shape[:2]]\n",
    "video = process_images(video, image_processor, model.config)\n",
    "video = [item.unsqueeze(0) for item in video]\n",
    "\n",
    "qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + qs\n",
    "conv = conv_templates[\"llama3\"].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(model.device)\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        images=video,\n",
    "        image_sizes=image_sizes,\n",
    "        do_sample=False,\n",
    "        temperature=0.2,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        stopping_criteria=[stopping_criteria],\n",
    "    )\n",
    "pred = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "print(f\"\\nAnswer: {pred}\") # 4bit -> 11G GPU ; 8 bit -> 12G GPU 视频长度如果是5秒，则需要9G GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b380b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The video begins with a scene featuring two characters in a fantastical setting, where one character, dressed in a bright yellow and red outfit with a mask, is seen in a dynamic pose suggesting movement or action, while the other character, an older figure with a white beard and a blue robe, stands with a contemplative expression. The background is filled with green foliage and a mountainous landscape, indicating an outdoor setting.\n",
      "\n",
      "As the video progresses, the character in the yellow and red outfit is seen in a more dynamic pose, with one arm raised, possibly signaling a gesture or movement, while the older character's expression becomes more concerned or surprised\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from longvu.builder import load_pretrained_model\n",
    "from longvu.constants import (\n",
    "    DEFAULT_IMAGE_TOKEN,\n",
    "    IMAGE_TOKEN_INDEX,\n",
    ")\n",
    "from longvu.conversation import conv_templates, SeparatorStyle\n",
    "from longvu.mm_datautils import (\n",
    "    KeywordsStoppingCriteria,\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    ")\n",
    "from decord import cpu, VideoReader\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    \"./checkpoints/LongVU_Qwen2_7B\", None, \"cambrian_qwen\",load_4bit=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "video_path = \"./examples/video1.mp4\"\n",
    "qs = \"Describe this video in detail\"\n",
    "\n",
    "vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
    "fps = float(vr.get_avg_fps())\n",
    "frame_indices = np.array([i for i in range(0, len(vr), round(fps),)])\n",
    "video = []\n",
    "for frame_index in frame_indices:\n",
    "    img = vr[frame_index].asnumpy()\n",
    "    video.append(img)\n",
    "video = np.stack(video)\n",
    "image_sizes = [video[0].shape[:2]]\n",
    "video = process_images(video, image_processor, model.config)\n",
    "video = [item.unsqueeze(0) for item in video]\n",
    "\n",
    "qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + qs\n",
    "conv = conv_templates[\"qwen\"].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(model.device)\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        images=video,\n",
    "        image_sizes=image_sizes,\n",
    "        do_sample=False,\n",
    "        temperature=0.2,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        stopping_criteria=[stopping_criteria],\n",
    "    )\n",
    "pred = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "print(f\"\\nAnswer: {pred}\") #17G GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8feefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cambrian from ./checkpoints/LongVU_Llama3_2_1B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The prompt to generate the video is \"a man in a yellow costume and a man in a blue outfit\".\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from longvu.builder import load_pretrained_model\n",
    "from longvu.constants import (\n",
    "    DEFAULT_IMAGE_TOKEN,\n",
    "    IMAGE_TOKEN_INDEX,\n",
    ")\n",
    "from longvu.conversation import conv_templates, SeparatorStyle\n",
    "from longvu.mm_datautils import (\n",
    "    KeywordsStoppingCriteria,\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    ")\n",
    "from decord import cpu, VideoReader\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    \"./checkpoints/LongVU_Llama3_2_1B\", None, \"cambrian_llama\",load_8bit=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "video_path = \"./examples/video1.mp4\"\n",
    "qs = \"What's the prompt to generate the video?\"\n",
    "\n",
    "vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
    "fps = float(vr.get_avg_fps())\n",
    "frame_indices = np.array([i for i in range(0, len(vr), round(fps),)])\n",
    "video = []\n",
    "for frame_index in frame_indices:\n",
    "    img = vr[frame_index].asnumpy()\n",
    "    video.append(img)\n",
    "video = np.stack(video)\n",
    "image_sizes = [video[0].shape[:2]]\n",
    "video = process_images(video, image_processor, model.config)\n",
    "video = [item.unsqueeze(0) for item in video]\n",
    "\n",
    "qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + qs\n",
    "conv = conv_templates[\"llama3\"].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(model.device)\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        images=video,\n",
    "        image_sizes=image_sizes,\n",
    "        do_sample=False,\n",
    "        temperature=0.2,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        stopping_criteria=[stopping_criteria],\n",
    "    )\n",
    "pred = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "print(f\"\\nAnswer: {pred}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e266c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cambrian from new_checkpoints/cambrian_llama3_2_1B_25epoches/checkpoint-6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: new_checkpoints/cambrian_llama3_2_1B_25epoches/checkpoint-6000\n",
      "Answer: a bird with a blue face and orange beak\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from longvu.builder import load_pretrained_model\n",
    "from longvu.constants import (\n",
    "    DEFAULT_IMAGE_TOKEN,\n",
    "    IMAGE_TOKEN_INDEX,\n",
    ")\n",
    "from longvu.conversation import conv_templates, SeparatorStyle\n",
    "from longvu.mm_datautils import (\n",
    "    KeywordsStoppingCriteria,\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    ")\n",
    "from decord import cpu, VideoReader\n",
    "\n",
    "model_path = \"new_checkpoints/cambrian_llama3_2_1B_25epoches/checkpoint-6000\"\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path, None, \"cambrian_llama\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "video_path = \"/home/fenghe/vidprom/cog_videos_example/cog-de3c22e1-6a93-5971-b09b-fc976ddd7803.mp4\"\n",
    "qs = \"What's the prompt to generate the video?\"\n",
    "\n",
    "vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
    "fps = float(vr.get_avg_fps())\n",
    "frame_indices = np.array([i for i in range(0, len(vr), round(fps),)])\n",
    "video = []\n",
    "for frame_index in frame_indices:\n",
    "    img = vr[frame_index].asnumpy()\n",
    "    video.append(img)\n",
    "video = np.stack(video)\n",
    "image_sizes = [video[0].shape[:2]]\n",
    "video = process_images(video, image_processor, model.config)\n",
    "video = [item.unsqueeze(0) for item in video]\n",
    "\n",
    "qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + qs\n",
    "conv = conv_templates[\"llama3\"].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(model.device)\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        images=video,\n",
    "        image_sizes=image_sizes,\n",
    "        do_sample=False,\n",
    "        temperature=0.2,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        stopping_criteria=[stopping_criteria],\n",
    "    )\n",
    "pred = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "print(f\"Model: {model_path}\\nAnswer: {pred}\") \n",
    "\n",
    "with open('video_inversion_answer.txt', 'a') as f:\n",
    "    f.write(f\"Model: {model_path}\\nAnswer: {pred}\\n\\n\")\n",
    "\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf152c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cambrian from new_checkpoints/cambrian_llama3_2_1B_35epoches/checkpoint-35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/fenghe/anaconda3/envs/longvu/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: new_checkpoints/cambrian_llama3_2_1B_35epoches/checkpoint-35000\n",
      "Answer: a woman with long hair and a white dress\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from longvu.builder import load_pretrained_model\n",
    "from longvu.constants import (\n",
    "    DEFAULT_IMAGE_TOKEN,\n",
    "    IMAGE_TOKEN_INDEX,\n",
    ")\n",
    "from longvu.conversation import conv_templates, SeparatorStyle\n",
    "from longvu.mm_datautils import (\n",
    "    KeywordsStoppingCriteria,\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    ")\n",
    "from decord import cpu, VideoReader\n",
    "\n",
    "model_path = \"new_checkpoints/cambrian_llama3_2_1B_35epoches/checkpoint-35000\"\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path, None, \"cambrian_llama\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "video_path = \"/home/fenghe/vidprom/cog_videos_example/cog-0010fb2b-f6cd-51af-a0b6-b38812f965ea.mp4\"\n",
    "qs = \"What's the prompt to generate the video?\"\n",
    "\n",
    "vr = VideoReader(video_path, ctx=cpu(0), num_threads=1)\n",
    "fps = float(vr.get_avg_fps())\n",
    "frame_indices = np.array([i for i in range(0, len(vr), round(fps),)])\n",
    "video = []\n",
    "for frame_index in frame_indices:\n",
    "    img = vr[frame_index].asnumpy()\n",
    "    video.append(img)\n",
    "video = np.stack(video)\n",
    "image_sizes = [video[0].shape[:2]]\n",
    "video = process_images(video, image_processor, model.config)\n",
    "video = [item.unsqueeze(0) for item in video]\n",
    "\n",
    "qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + qs\n",
    "conv = conv_templates[\"llama3\"].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(model.device)\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        images=video,\n",
    "        image_sizes=image_sizes,\n",
    "        do_sample=False,\n",
    "        temperature=0.2,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        stopping_criteria=[stopping_criteria],\n",
    "    )\n",
    "pred = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "print(f\"Model: {model_path}\\nAnswer: {pred}\") \n",
    "\n",
    "with open('video_inversion_answer.txt', 'a') as f:\n",
    "    f.write(f\"Model: {model_path}\\nAnswer: {pred}\\n\\n\")\n",
    "\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "613ceb3b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Model: /home/fenghe/LongVU/new_checkpoints/cambrian_llama3_2_1B\n",
    "Answer: a man playing the saxophone in a garden\n",
    "\n",
    "Model: new_checkpoints/cambrian_llama3_2_1B_3epoches/checkpoint-3750\n",
    "Answer: a man playing saxophone in a garden\n",
    "\n",
    "Model: new_checkpoints/cambrian_llama3_2_1B_2epoches/checkpoint-2500\n",
    "Answer: a man playing saxophone in a garden"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbb2b5f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec67ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 读取video_prompts.json\n",
    "with open('video_prompts.json', 'r') as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "# 将prompts转换为DataFrame\n",
    "df = pd.DataFrame(prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c332e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_df = df.sample(frac=0.9, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# 保存训练集和测试集，保留原来json的格式\n",
    "with open('train_prompts_90percent.json', 'w') as f:\n",
    "    json.dump(train_df.to_dict(orient='records'), f, indent=2)\n",
    "\n",
    "with open('test_prompts_10percent.json', 'w') as f:\n",
    "    json.dump(test_df.to_dict(orient='records'), f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbc78cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/cogvid_2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 23:19:35,881] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda-12.4/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda-12.4/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda-12.4/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda-12.4/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int*@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for long*@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/home/fenghe/anaconda3/envs/cogvid_2/compiler_compat/ld: /usr/local/cuda-12.4/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.75it/s]\n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  8.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import CogVideoXPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "pipe = CogVideoXPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# pipe.enable_model_cpu_offload()\n",
    "# pipe.enable_sequential_cpu_offload()\n",
    "pipe.to(\"cuda\") \n",
    "pipe.vae.enable_slicing()\n",
    "pipe.vae.enable_tiling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947a38d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:25<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"a purple car driving on the highway\"\n",
    "video = pipe(\n",
    "    prompt=prompt,\n",
    "    num_videos_per_prompt=1,\n",
    "    num_inference_steps=50,\n",
    "    num_frames=49,\n",
    "    guidance_scale=6,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(66),\n",
    ").frames[0]\n",
    "\n",
    "export_to_video(video, \"output/specific_examples/output_8.mp4\", fps=8)\n",
    "\n",
    "if 'pipe' in globals():\n",
    "    del video\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324174b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/5 [02:48<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# To get started, PytorchAO needs to be installed from the GitHub source and PyTorch Nightly.\n",
    "# Source and nightly installation is only required until next release.\n",
    "\n",
    "import torch\n",
    "from diffusers import AutoencoderKLCogVideoX, CogVideoXTransformer3DModel, CogVideoXPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "# from transformers import T5EncoderModel\n",
    "# from torchao.quantization import quantize_, int8_weight_only, int8_dynamic_activation_int8_weight\n",
    "\n",
    "# quantization = int8_weight_only\n",
    "\n",
    "# text_encoder = T5EncoderModel.from_pretrained(\"THUDM/CogVideoX-5b\", subfolder=\"text_encoder\", torch_dtype=torch.bfloat16)\n",
    "# quantize_(text_encoder, quantization())\n",
    "\n",
    "# transformer = CogVideoXTransformer3DModel.from_pretrained(\"THUDM/CogVideoX-5b\", subfolder=\"transformer\", torch_dtype=torch.bfloat16)\n",
    "# quantize_(transformer, quantization())\n",
    "\n",
    "# vae = AutoencoderKLCogVideoX.from_pretrained(\"THUDM/CogVideoX-2b\", subfolder=\"vae\", torch_dtype=torch.bfloat16)\n",
    "# quantize_(vae, quantization())\n",
    "\n",
    "# Create pipeline and run inference\n",
    "pipe = CogVideoXPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    # text_encoder=text_encoder,\n",
    "    # transformer=transformer,\n",
    "    # vae=vae,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "pipe.enable_model_cpu_offload()\n",
    "pipe.vae.enable_tiling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbcced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"A woman is smoking a cigarette while sitting on a bed.\"\n",
    "\n",
    "video = pipe(\n",
    "    prompt=prompt,\n",
    "    num_videos_per_prompt=1,\n",
    "    num_inference_steps=50,\n",
    "    num_frames=49,\n",
    "    guidance_scale=6,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    ").frames[0]\n",
    "\n",
    "export_to_video(video, \"output.mp4\", fps=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c2e38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "longvu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
