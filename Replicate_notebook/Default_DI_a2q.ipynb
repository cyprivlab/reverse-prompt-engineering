{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and re-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T10:00:39.285937Z",
     "start_time": "2025-05-07T10:00:39.283576Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset,load_from_disk,Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T10:12:45.124847Z",
     "start_time": "2025-05-07T10:12:44.997877Z"
    }
   },
   "outputs": [],
   "source": [
    "# ÂØºÂÖ•ËÆ≠ÁªÉ‰∏éÊµãËØïÊï∞ÊçÆÈõÜ\n",
    "# train_dataset_df = pd.read_parquet('datasets/alpaca-0.2-train') # datasets/alpaca-0.2-train\n",
    "# test_dataset_df = pd.read_parquet('datasets/alpaca-0.2-test')  # datasets/alpaca-0.2-test\n",
    "datasets_name = 'gptrqa' # 'alpaca'/'gptrqa'\n",
    "\n",
    "if datasets_name == 'alpaca':\n",
    "    train_dataset_df = load_from_disk('datasets/alpaca-0.2-train') # datasets/alpaca-0.2-train\n",
    "    test_dataset_df = load_from_disk('datasets/alpaca-0.2-test')   # datasets/alpaca-0.2-test\n",
    "else:\n",
    "    train_dataset_df = load_from_disk('datasets/GPTRQA-train') # datasets/alpaca-0.2-train\n",
    "    test_dataset_df = load_from_disk('datasets/GPTRQA-test')   # datasets/alpaca-0.2-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c8663fca-1e80-4fca-932e-d5d379df3d47",
       "rows": [
        [
         "0",
         "Why do electronics stop working after they are submerged by water ? I could understand if they have power running through them , but what about electronics that are powered off completely ? Explain like I'm five.",
         "Water is a conductor of electricity, which means it can allow electrical current to flow through it. When an electronic device is submerged in water, the water can get into the device and come into contact with the electrical components inside. This can cause a short circuit, which is when electricity flows through an unintended path and can cause damage to the device.\\n\\nEven if the device is powered off, the water can still get inside and cause damage. For example, the water can corrode or rust the metal components inside the device, which can make it stop working properly.\\n\\nSo, to sum it up, electronics can stop working after they are submerged in water because the water can cause a short circuit or damage the internal components.",
         "0",
         "answer: Water is a conductor of electricity, which means it can allow electrical current to flow through it. When an electronic device is submerged in water, the water can get into the device and come into contact with the electrical components inside. This can cause a short circuit, which is when electricity flows through an unintended path and can cause damage to the device.\\n\\nEven if the device is powered off, the water can still get inside and cause damage. For example, the water can corrode or rust the metal components inside the device, which can make it stop working properly.\\n\\nSo, to sum it up, electronics can stop working after they are submerged in water because the water can cause a short circuit or damage the internal components.",
         "enquiry: Why do electronics stop working after they are submerged by water ? I could understand if they have power running through them , but what about electronics that are powered off completely ? Explain like I'm five."
        ],
        [
         "1",
         "what are k cups",
         "K-Cups are single-serve coffee pods that are used in coffee makers, specifically those that are compatible with the Keurig brewing system. Each K-Cup contains a predetermined amount of ground coffee, tea, hot cocoa, or other drink mix. To use a K-Cup, you place it in the coffee maker and press a button to start the brewing process. The coffee maker punctures the K-Cup and extracts the contents, resulting in a freshly brewed cup of coffee, tea, or other drink. K-Cups are convenient because they allow you to quickly and easily brew a single serving of your favorite beverage without the need for measuring and grinding beans or loose leaf tea. However, some people criticize K-Cups for their environmental impact, as the pods are not easily recyclable and can contribute to waste.",
         "1",
         "answer: K-Cups are single-serve coffee pods that are used in coffee makers, specifically those that are compatible with the Keurig brewing system. Each K-Cup contains a predetermined amount of ground coffee, tea, hot cocoa, or other drink mix. To use a K-Cup, you place it in the coffee maker and press a button to start the brewing process. The coffee maker punctures the K-Cup and extracts the contents, resulting in a freshly brewed cup of coffee, tea, or other drink. K-Cups are convenient because they allow you to quickly and easily brew a single serving of your favorite beverage without the need for measuring and grinding beans or loose leaf tea. However, some people criticize K-Cups for their environmental impact, as the pods are not easily recyclable and can contribute to waste.",
         "enquiry: what are k cups"
        ],
        [
         "2",
         "Self Assessment UK - Goods and services for your own use",
         "In the UK, self assessment is a system used by individuals to report their income and pay tax on it. Under self assessment, individuals are responsible for declaring their own income and calculating the tax they owe. This includes income from employment, self-employment, and other sources such as rental income or savings and investments.If you are using goods or services for your own personal use, rather than for business or rental purposes, you may not be required to pay VAT (value-added tax) on those goods or services. However, there are some exceptions to this rule. For example, if you purchase a good or service with the intention of reselling it, you may be required to pay VAT. It is important to check with HM Revenue and Customs (HMRC) or seek advice from a tax professional if you are unsure about whether VAT applies to a particular transaction.It is also important to note that you may be required to pay tax on any income you receive from using goods or services for your own personal use, such as if you earn money from renting out a room in your home on a short-term basis. In this case, you may need to report this income as part of your self assessment and pay tax on it.If you are required to file a self assessment tax return, you will need to declare all of your income and pay any tax owed by the deadline for submitting your return. If you fail to do so, you may be subject to penalties and interest charges. It is important to keep accurate records of your income and any expenses you incur so that you can accurately report your income and pay the correct amount of tax.",
         "2",
         "answer: In the UK, self assessment is a system used by individuals to report their income and pay tax on it. Under self assessment, individuals are responsible for declaring their own income and calculating the tax they owe. This includes income from employment, self-employment, and other sources such as rental income or savings and investments.If you are using goods or services for your own personal use, rather than for business or rental purposes, you may not be required to pay VAT (value-added tax) on those goods or services. However, there are some exceptions to this rule. For example, if you purchase a good or service with the intention of reselling it, you may be required to pay VAT. It is important to check with HM Revenue and Customs (HMRC) or seek advice from a tax professional if you are unsure about whether VAT applies to a particular transaction.It is also important to note that you may be required to pay tax on any income you receive from using goods or services for your own personal use, such as if you earn money from renting out a room in your home on a short-term basis. In this case, you may need to report this income as part of your self assessment and pay tax on it.If you are required to file a self assessment tax return, you will need to declare all of your income and pay any tax owed by the deadline for submitting your return. If you fail to do so, you may be subject to penalties and interest charges. It is important to keep accurate records of your income and any expenses you incur so that you can accurately report your income and pay the correct amount of tax.",
         "enquiry: Self Assessment UK - Goods and services for your own use"
        ],
        [
         "3",
         "Why do police officers have bullet proof vests for covering vital organs when often times they leave their heads unprotected ? I understand that SWAT teams and riot folks have helmets , but what about regular police ? Explain like I'm five.",
         "Police officers wear bulletproof vests to protect their vital organs, like their heart and lungs, because those organs are very important for their bodies to function properly. The vests are made of special materials that are designed to stop bullets from penetrating the body and causing injury or death.  However, police officers do not always wear helmets because they can be heavy and uncomfortable, and they might not be practical for all types of police work. In some situations, like when officers are patrolling a neighborhood or responding to a call, a helmet might not be necessary because there is not a high risk of being shot.  In other situations, like when officers are responding to an active shooter or engaging in a high-risk operation, they might wear a helmet to protect their head. Special units like SWAT teams, who are trained to handle high-risk situations, often wear helmets as part of their protective gear.  Overall, police officers try to balance the need for protection with the need to be able to move and respond quickly to different situations.",
         "3",
         "answer: Police officers wear bulletproof vests to protect their vital organs, like their heart and lungs, because those organs are very important for their bodies to function properly. The vests are made of special materials that are designed to stop bullets from penetrating the body and causing injury or death.  However, police officers do not always wear helmets because they can be heavy and uncomfortable, and they might not be practical for all types of police work. In some situations, like when officers are patrolling a neighborhood or responding to a call, a helmet might not be necessary because there is not a high risk of being shot.  In other situations, like when officers are responding to an active shooter or engaging in a high-risk operation, they might wear a helmet to protect their head. Special units like SWAT teams, who are trained to handle high-risk situations, often wear helmets as part of their protective gear.  Overall, police officers try to balance the need for protection with the need to be able to move and respond quickly to different situations.",
         "enquiry: Why do police officers have bullet proof vests for covering vital organs when often times they leave their heads unprotected ? I understand that SWAT teams and riot folks have helmets , but what about regular police ? Explain like I'm five."
        ],
        [
         "4",
         "How does an anarcho - socialist society prevent a resurgence of capitalism , and how does an anarchist society in general prevent crime ? To me anarchy seems like a good idea in theory but has fundamental problems with implementation . Please explain like I'm five.",
         "An anarcho-socialist society is one in which there is no government or state to enforce laws, but instead, the community is organized to meet the needs of all its members and make decisions collectively. This type of society is based on the idea that people can work together and cooperate without the need for a centralized authority. To prevent a resurgence of capitalism in an anarcho-socialist society, it would be important to challenge the idea that profit and private ownership are necessary for society to function. Instead, resources and decision-making would be controlled by the community as a whole, rather than by a small group of individuals. To prevent crime in an anarchist society, it would be important to focus on addressing the root causes of crime, such as poverty, inequality, and social injustice. Instead of relying on punishment and incarceration, an anarchist society might try to solve problems through education, restorative justice, and community-based approaches to conflict resolution. It is important to note that no society is perfect, and there will always be challenges to overcome. However, an anarchist society is based on the idea that people can work together and solve problems without relying on a central authority or hierarchy. This requires trust, cooperation, and a willingness to work together towards common goals.",
         "4",
         "answer: An anarcho-socialist society is one in which there is no government or state to enforce laws, but instead, the community is organized to meet the needs of all its members and make decisions collectively. This type of society is based on the idea that people can work together and cooperate without the need for a centralized authority. To prevent a resurgence of capitalism in an anarcho-socialist society, it would be important to challenge the idea that profit and private ownership are necessary for society to function. Instead, resources and decision-making would be controlled by the community as a whole, rather than by a small group of individuals. To prevent crime in an anarchist society, it would be important to focus on addressing the root causes of crime, such as poverty, inequality, and social injustice. Instead of relying on punishment and incarceration, an anarchist society might try to solve problems through education, restorative justice, and community-based approaches to conflict resolution. It is important to note that no society is perfect, and there will always be challenges to overcome. However, an anarchist society is based on the idea that people can work together and solve problems without relying on a central authority or hierarchy. This requires trust, cooperation, and a willingness to work together towards common goals.",
         "enquiry: How does an anarcho - socialist society prevent a resurgence of capitalism , and how does an anarchist society in general prevent crime ? To me anarchy seems like a good idea in theory but has fundamental problems with implementation . Please explain like I'm five."
        ],
        [
         "5",
         "[ META ] Why are people suddenly usingto ask loaded questions and make political statements ? Then cutely try to make it sound like a genuine question by saying something like : Just wondering what your opinions on this are . Please explain like I'm five.",
         "There could be a variety of reasons why people might ask loaded questions or make political statements in the form of a question. It's possible that they are trying to gauge other people's opinions on a particular topic, or they may be trying to promote a certain viewpoint. They may also be trying to start a conversation or debate about the topic in question. As for the \"explain like I'm five\" part of the question, this is often used as a way to ask for a simplified or straightforward explanation of a complex or controversial topic. It's a way of asking for a clear and easy-to-understand explanation without any unnecessary details or jargon.",
         "5",
         "answer: There could be a variety of reasons why people might ask loaded questions or make political statements in the form of a question. It's possible that they are trying to gauge other people's opinions on a particular topic, or they may be trying to promote a certain viewpoint. They may also be trying to start a conversation or debate about the topic in question. As for the \"explain like I'm five\" part of the question, this is often used as a way to ask for a simplified or straightforward explanation of a complex or controversial topic. It's a way of asking for a clear and easy-to-understand explanation without any unnecessary details or jargon.",
         "enquiry: [ META ] Why are people suddenly usingto ask loaded questions and make political statements ? Then cutely try to make it sound like a genuine question by saying something like : Just wondering what your opinions on this are . Please explain like I'm five."
        ],
        [
         "6",
         "- Does the little amount of energy used in a hand dryer really affect the environment less than the 2 paper towels they replaced ? It sounds like the difference would be nearly immeasurable in the first place . Please explain like I'm five.",
         "The amount of energy used by a hand dryer is small compared to other household appliances, but it is still important to consider the environmental impact of using it. When we use a hand dryer, we are using electricity, which typically comes from burning fossil fuels like coal or natural gas. These fuels release greenhouse gases like carbon dioxide into the atmosphere, which contribute to climate change. On the other hand, paper towels are made from trees, which absorb carbon dioxide as they grow. When we use paper towels, we are using a natural resource that helps to remove carbon dioxide from the atmosphere. So, while the difference in energy use between a hand dryer and two paper towels may be small, the difference in their environmental impact is significant.",
         "6",
         "answer: The amount of energy used by a hand dryer is small compared to other household appliances, but it is still important to consider the environmental impact of using it. When we use a hand dryer, we are using electricity, which typically comes from burning fossil fuels like coal or natural gas. These fuels release greenhouse gases like carbon dioxide into the atmosphere, which contribute to climate change. On the other hand, paper towels are made from trees, which absorb carbon dioxide as they grow. When we use paper towels, we are using a natural resource that helps to remove carbon dioxide from the atmosphere. So, while the difference in energy use between a hand dryer and two paper towels may be small, the difference in their environmental impact is significant.",
         "enquiry: - Does the little amount of energy used in a hand dryer really affect the environment less than the 2 paper towels they replaced ? It sounds like the difference would be nearly immeasurable in the first place . Please explain like I'm five."
        ],
        [
         "7",
         "why do sirens change pitch so significantly when you drive by them ? Not the general siren sound but how when you drive by as soon as you pass by it it seems to lower a key or two . Edit : thanks for the answers ! Please explain like I'm five.",
         "When you are driving by a siren, the pitch of the sound seems to change because of something called the Doppler effect. The Doppler effect is a change in the frequency or pitch of a sound wave that occurs when the source of the sound and the listener are moving relative to each other. For example, when a siren on an ambulance is approaching you, the sound waves it is emitting are compressed, or squeezed together. This makes the pitch of the siren sound higher. As the ambulance passes by you and moves away, the sound waves it is emitting are stretched out, which makes the pitch of the siren sound lower. This is similar to what happens when a car with a loud horn drives by you. The pitch of the horn seems to change as the car approaches and then moves away from you. So, when you are driving by a siren, the pitch of the sound seems to change because the source of the sound (the ambulance or fire truck) is moving relative to you, and the Doppler effect causes the pitch of the sound to change.",
         "7",
         "answer: When you are driving by a siren, the pitch of the sound seems to change because of something called the Doppler effect. The Doppler effect is a change in the frequency or pitch of a sound wave that occurs when the source of the sound and the listener are moving relative to each other. For example, when a siren on an ambulance is approaching you, the sound waves it is emitting are compressed, or squeezed together. This makes the pitch of the siren sound higher. As the ambulance passes by you and moves away, the sound waves it is emitting are stretched out, which makes the pitch of the siren sound lower. This is similar to what happens when a car with a loud horn drives by you. The pitch of the horn seems to change as the car approaches and then moves away from you. So, when you are driving by a siren, the pitch of the sound seems to change because the source of the sound (the ambulance or fire truck) is moving relative to you, and the Doppler effect causes the pitch of the sound to change.",
         "enquiry: why do sirens change pitch so significantly when you drive by them ? Not the general siren sound but how when you drive by as soon as you pass by it it seems to lower a key or two . Edit : thanks for the answers ! Please explain like I'm five."
        ],
        [
         "8",
         "Why do some states call themselves commonwealths instead of just ' state of .. \" For example , Virginia and Massachusetts Please explain like I'm five.",
         "A commonwealth is a type of government in which the people have a say in how the government is run and the government is set up to benefit the common good of the people. The term \"commonwealth\" is often used to describe a group of people who work together for the benefit of everyone. The states of Virginia and Massachusetts were both founded as English colonies and were originally called the \"Commonwealth of Virginia\" and the \"Commonwealth of Massachusetts.\" Even though they are now part of the United States and are called states, they have chosen to keep the word \"commonwealth\" in their official names to reflect their history and the idea of working together for the common good. So, in short, Virginia and Massachusetts are called commonwealths because they have a long history of working together for the benefit of all their citizens.",
         "8",
         "answer: A commonwealth is a type of government in which the people have a say in how the government is run and the government is set up to benefit the common good of the people. The term \"commonwealth\" is often used to describe a group of people who work together for the benefit of everyone. The states of Virginia and Massachusetts were both founded as English colonies and were originally called the \"Commonwealth of Virginia\" and the \"Commonwealth of Massachusetts.\" Even though they are now part of the United States and are called states, they have chosen to keep the word \"commonwealth\" in their official names to reflect their history and the idea of working together for the common good. So, in short, Virginia and Massachusetts are called commonwealths because they have a long history of working together for the benefit of all their citizens.",
         "enquiry: Why do some states call themselves commonwealths instead of just ' state of .. \" For example , Virginia and Massachusetts Please explain like I'm five."
        ],
        [
         "9",
         "How do student loans influence college tuition ? With the situation at UC Berkeley , I 'd really like to understand what student loans actually mean in terms of their relation to the government . Please explain like I'm five.",
         "Student loans are a type of financial aid that students can use to help pay for their college education. These loans are typically provided by the government, but can also be offered by banks and other private lenders. When a student takes out a student loan, they are borrowing money from the lender to pay for their tuition and other education-related expenses. The student is then responsible for repaying the loan, with interest, after they graduate or leave school. The amount of student loan funding available can impact the cost of tuition at a college or university. If there is a lot of funding available, schools may be able to charge lower tuition fees because they know that students will be able to borrow money to pay for their education. On the other hand, if there is less funding available, schools may need to increase tuition to make up for the lack of funding. It's important to note that student loans can have a significant impact on a student's financial situation after they graduate. It's important for students to carefully consider their options and understand the terms of any student loans they take out before committing to borrowing money.",
         "9",
         "answer: Student loans are a type of financial aid that students can use to help pay for their college education. These loans are typically provided by the government, but can also be offered by banks and other private lenders. When a student takes out a student loan, they are borrowing money from the lender to pay for their tuition and other education-related expenses. The student is then responsible for repaying the loan, with interest, after they graduate or leave school. The amount of student loan funding available can impact the cost of tuition at a college or university. If there is a lot of funding available, schools may be able to charge lower tuition fees because they know that students will be able to borrow money to pay for their education. On the other hand, if there is less funding available, schools may need to increase tuition to make up for the lack of funding. It's important to note that student loans can have a significant impact on a student's financial situation after they graduate. It's important for students to carefully consider their options and understand the terms of any student loans they take out before committing to borrowing money.",
         "enquiry: How do student loans influence college tuition ? With the situation at UC Berkeley , I 'd really like to understand what student loans actually mean in terms of their relation to the government . Please explain like I'm five."
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>index</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do electronics stop working after they are...</td>\n",
       "      <td>Water is a conductor of electricity, which mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>answer: Water is a conductor of electricity, w...</td>\n",
       "      <td>enquiry: Why do electronics stop working after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are k cups</td>\n",
       "      <td>K-Cups are single-serve coffee pods that are u...</td>\n",
       "      <td>1</td>\n",
       "      <td>answer: K-Cups are single-serve coffee pods th...</td>\n",
       "      <td>enquiry: what are k cups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self Assessment UK - Goods and services for yo...</td>\n",
       "      <td>In the UK, self assessment is a system used by...</td>\n",
       "      <td>2</td>\n",
       "      <td>answer: In the UK, self assessment is a system...</td>\n",
       "      <td>enquiry: Self Assessment UK - Goods and servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why do police officers have bullet proof vests...</td>\n",
       "      <td>Police officers wear bulletproof vests to prot...</td>\n",
       "      <td>3</td>\n",
       "      <td>answer: Police officers wear bulletproof vests...</td>\n",
       "      <td>enquiry: Why do police officers have bullet pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does an anarcho - socialist society preven...</td>\n",
       "      <td>An anarcho-socialist society is one in which t...</td>\n",
       "      <td>4</td>\n",
       "      <td>answer: An anarcho-socialist society is one in...</td>\n",
       "      <td>enquiry: How does an anarcho - socialist socie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ META ] Why are people suddenly usingto ask l...</td>\n",
       "      <td>There could be a variety of reasons why people...</td>\n",
       "      <td>5</td>\n",
       "      <td>answer: There could be a variety of reasons wh...</td>\n",
       "      <td>enquiry: [ META ] Why are people suddenly usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>- Does the little amount of energy used in a h...</td>\n",
       "      <td>The amount of energy used by a hand dryer is s...</td>\n",
       "      <td>6</td>\n",
       "      <td>answer: The amount of energy used by a hand dr...</td>\n",
       "      <td>enquiry: - Does the little amount of energy us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>why do sirens change pitch so significantly wh...</td>\n",
       "      <td>When you are driving by a siren, the pitch of ...</td>\n",
       "      <td>7</td>\n",
       "      <td>answer: When you are driving by a siren, the p...</td>\n",
       "      <td>enquiry: why do sirens change pitch so signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why do some states call themselves commonwealt...</td>\n",
       "      <td>A commonwealth is a type of government in whic...</td>\n",
       "      <td>8</td>\n",
       "      <td>answer: A commonwealth is a type of government...</td>\n",
       "      <td>enquiry: Why do some states call themselves co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do student loans influence college tuition...</td>\n",
       "      <td>Student loans are a type of financial aid that...</td>\n",
       "      <td>9</td>\n",
       "      <td>answer: Student loans are a type of financial ...</td>\n",
       "      <td>enquiry: How do student loans influence colleg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Why do electronics stop working after they are...   \n",
       "1                                    what are k cups   \n",
       "2  Self Assessment UK - Goods and services for yo...   \n",
       "3  Why do police officers have bullet proof vests...   \n",
       "4  How does an anarcho - socialist society preven...   \n",
       "5  [ META ] Why are people suddenly usingto ask l...   \n",
       "6  - Does the little amount of energy used in a h...   \n",
       "7  why do sirens change pitch so significantly wh...   \n",
       "8  Why do some states call themselves commonwealt...   \n",
       "9  How do student loans influence college tuition...   \n",
       "\n",
       "                                              answer  index  \\\n",
       "0  Water is a conductor of electricity, which mea...      0   \n",
       "1  K-Cups are single-serve coffee pods that are u...      1   \n",
       "2  In the UK, self assessment is a system used by...      2   \n",
       "3  Police officers wear bulletproof vests to prot...      3   \n",
       "4  An anarcho-socialist society is one in which t...      4   \n",
       "5  There could be a variety of reasons why people...      5   \n",
       "6  The amount of energy used by a hand dryer is s...      6   \n",
       "7  When you are driving by a siren, the pitch of ...      7   \n",
       "8  A commonwealth is a type of government in whic...      8   \n",
       "9  Student loans are a type of financial aid that...      9   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  answer: Water is a conductor of electricity, w...   \n",
       "1  answer: K-Cups are single-serve coffee pods th...   \n",
       "2  answer: In the UK, self assessment is a system...   \n",
       "3  answer: Police officers wear bulletproof vests...   \n",
       "4  answer: An anarcho-socialist society is one in...   \n",
       "5  answer: There could be a variety of reasons wh...   \n",
       "6  answer: The amount of energy used by a hand dr...   \n",
       "7  answer: When you are driving by a siren, the p...   \n",
       "8  answer: A commonwealth is a type of government...   \n",
       "9  answer: Student loans are a type of financial ...   \n",
       "\n",
       "                                         target_text  \n",
       "0  enquiry: Why do electronics stop working after...  \n",
       "1                           enquiry: what are k cups  \n",
       "2  enquiry: Self Assessment UK - Goods and servic...  \n",
       "3  enquiry: Why do police officers have bullet pr...  \n",
       "4  enquiry: How does an anarcho - socialist socie...  \n",
       "5  enquiry: [ META ] Why are people suddenly usin...  \n",
       "6  enquiry: - Does the little amount of energy us...  \n",
       "7  enquiry: why do sirens change pitch so signifi...  \n",
       "8  enquiry: Why do some states call themselves co...  \n",
       "9  enquiry: How do student loans influence colleg...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ê£ÄÊü•Êï∞ÊçÆÈõÜÂ§¥10Êù°Êï∞ÊçÆÁöÑÊÉÖÂÜµ\n",
    "pd.DataFrame(test_dataset_df).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DI-t5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰∏ªË¶ÅÂ∑•‰ΩúÈÉ®ÂàÜÔºåÂ∞±ÊòØÁúãÂàíÂàÜÂá∫Êù•ÁöÑÊï∞ÊçÆÈõÜÊòØÂê¶‰ºöÂΩ±ÂìçÊ®°ÂûãÁöÑËæìÂá∫ÔºàÊÉ≥Ë¶ÅËøΩÊ±ÇÁöÑÁªìÊûúÔºöÂàíÂàÜ‰∏çÂ§™‰ºöÂΩ±ÂìçÁªìÊûúÔºâ\n",
    "split_size = 0.2 #ÊØî‰æã‰∏∫0.2-0.5\n",
    "train_test_split_t5 = train_dataset_df.train_test_split(test_size=split_size, seed=42) #seed‰øùËØÅÂèØÂ§çÁé∞\n",
    "train_dataset_t5 = train_test_split_t5['train']\n",
    "val_dataset_t5 = train_test_split_t5['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed36d5bc6bca45ccbd50f0ec24abb768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/13363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecc7eb746d84ab38a187b25efdde493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_t5.save_to_disk(dataset_path=f'ablation/split_dataset/{datasets_name}/{datasets_name}_{split_size}-train')\n",
    "val_dataset_t5.save_to_disk(dataset_path=f'ablation/split_dataset/{datasets_name}/{datasets_name}_{split_size}-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂàùÂßãÂåñtokenizer\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "def tokenize_t5_function(examples):\n",
    "    model_inputs = t5_tokenizer(examples['input_text'], padding=\"max_length\", truncation=True)\n",
    "    labels = t5_tokenizer(examples['target_text'], padding=\"max_length\", truncation=True)\n",
    "    print(labels)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_train_dataset_t5 = train_dataset_t5.map(tokenize_t5_function, batched=True)\n",
    "tokenized_val_dataset_t5 = val_dataset_t5.map(tokenize_t5_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âä†ËΩΩÊ®°ÂûãÂà∞GPU\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path='ablation/DI/gptrqa/gptrqa_DI_t5_small_0.2_25e'\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/RL4LM/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "num_epoches = 25\n",
    "\n",
    "training_args_t5 = TrainingArguments(\n",
    "    output_dir= f'ablation/split_train_model/{datasets_name}_{split_size}/DI',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_epoches,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_t5 = Trainer(\n",
    "    model=t5_model,\n",
    "    args=training_args_t5,\n",
    "    train_dataset=tokenized_train_dataset_t5,\n",
    "    eval_dataset=tokenized_val_dataset_t5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10450' max='10450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10450/10450 2:10:57, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.209290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.202647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.199573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.197599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.196285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.196086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.194993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.195300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.195594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.195165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.195639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.195926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.196874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.196618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.197151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.197582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.197722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.198087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.198701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.198748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.199223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.199325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.199437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.199715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.199669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10450, training_loss=0.17106935345955443, metrics={'train_runtime': 7858.5032, 'train_samples_per_second': 42.511, 'train_steps_per_second': 1.33, 'total_flos': 4.52143123267584e+16, 'train_loss': 0.17106935345955443, 'epoch': 25.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÂºÄÂßãËÆ≠ÁªÉ\n",
    "trainer_t5.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ablation/DI/gptrqa/gptrqa_DI_t5_small_0.2_25e/tokenizer_config.json',\n",
       " 'ablation/DI/gptrqa/gptrqa_DI_t5_small_0.2_25e/special_tokens_map.json',\n",
       " 'ablation/DI/gptrqa/gptrqa_DI_t5_small_0.2_25e/spiece.model',\n",
       " 'ablation/DI/gptrqa/gptrqa_DI_t5_small_0.2_25e/added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‰øùÂ≠òÊ®°Âûã\n",
    "trainer_t5.save_model(f'ablation/DI/{datasets_name}/{datasets_name}_DI_t5_small_{split_size}_{num_epoches}e') \n",
    "t5_tokenizer.save_pretrained(f'ablation/DI/{datasets_name}/{datasets_name}_DI_t5_small_{split_size}_{num_epoches}e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(answer):\n",
    "    t5_model.eval()  # Â∞ÜÊ®°ÂûãËÆæÁΩÆ‰∏∫ËØÑ‰º∞Ê®°Âºè\n",
    "    input_ids = t5_tokenizer.encode(\"answer: \" + answer, return_tensors=\"pt\").to(device)\n",
    "    outputs = t5_model.generate(input_ids, num_beams=5, early_stopping=True)\n",
    "    question = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê†πÊçÆÂΩìÂâçË¶ÅËÆ≠ÁªÉÁöÑË∞ÉÊï¥ÂÖ®Â±ÄÊ®°ÂûãÂëΩÂêç‰ª•ÂèäÊ®°ÂûãÈ¢ÑÊµãÁªìÊûúÊñá‰ª∂ÂëΩÂêç\n",
    "DI_generation_texts_pth = f'ablation/GenText/{datasets_name}/DI_{datasets_name}_gen_{split_size}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10401 [00:00<?, ?it/s]/home/fenghe/anaconda3/envs/RL4LM/lib/python3.9/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "  1%|          | 55/10401 [00:06<22:06,  7.80it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10401/10401 [20:24<00:00,  8.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Ëé∑ÂèñÂá†‰∏™Ê†∑Êú¨\n",
    "samples = test_dataset_df  \n",
    "res = []\n",
    "# ÁîüÊàêÈóÆÈ¢òÂπ∂ÊØîËæÉ\n",
    "with open(DI_generation_texts_pth, 'w') as file:\n",
    "    for example in tqdm(samples):\n",
    "        generated_question = generate_question(example['input_text'])\n",
    "        res.append(generated_question.replace(\"enquiry: \", \"\"))\n",
    "        file.write((generated_question.replace(\"enquiry: \", \"\")+'\\n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bert_score import score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def Calmetic(references:list[list[str]], predictions:list[str]):\n",
    "    '''\n",
    "    Input format:\n",
    "\n",
    "    predictions = [\n",
    "        \"What is the capital of France?\",\n",
    "        \"Who wrote the book?\",\n",
    "        \"What is the largest planet?\"\n",
    "    ]\n",
    "\n",
    "    references = [\n",
    "        [\"What is the capital city of France?\"],\n",
    "        [\"Who is the author of the book?\"],\n",
    "        [\"Which planet is the largest in the solar system?\"]\n",
    "    ]\n",
    "    '''\n",
    "\n",
    "    # # Âä†ËΩΩ BLEU ËØÑÂàÜÂô®\n",
    "    # bleu_metric = load_metric(\"bleu\")\n",
    "\n",
    "    # # ËÆ°ÁÆó BLEU ÂàÜÊï∞\n",
    "    predictions_tokenized = [word_tokenize(pred) for pred in predictions]\n",
    "    references_tokenized = [[word_tokenize(refs[0])] for refs in references]\n",
    "    # B_S = {}\n",
    "    # for n in range(1, 5):\n",
    "    #     bleu_metric.add_batch(predictions=predictions_tokenized, references=references_tokenized)\n",
    "    #     results = bleu_metric.compute(max_order=n)\n",
    "    #     B_S[f\"BLEU-{n}\"] = results\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    B_S = bleu_metric.compute(predictions=predictions, references=references,tokenizer=word_tokenize)\n",
    "    for i,n in enumerate(B_S['precisions']):\n",
    "        print(f\"BLEU-{i+1} score: {n:.5f}\")\n",
    "        \n",
    "\n",
    "\n",
    "    # Âä†ËΩΩ ROUGE ËØÑÂàÜÂô®\n",
    "    rouge_metric = load_metric(\"rouge\")\n",
    "    '''\n",
    "    ROUGE-1: Ë°°ÈáèÁîüÊàêÊñáÊú¨ÂíåÂèÇËÄÉÊñáÊú¨‰πãÈó¥ÁöÑ unigram ÂåπÈÖç„ÄÇ\n",
    "    ROUGE-2: Ë°°ÈáèÁîüÊàêÊñáÊú¨ÂíåÂèÇËÄÉÊñáÊú¨‰πãÈó¥ÁöÑ bigram ÂåπÈÖç„ÄÇ\n",
    "    ROUGE-L: Ë°°ÈáèÁîüÊàêÊñáÊú¨ÂíåÂèÇËÄÉÊñáÊú¨‰πãÈó¥ÁöÑÊúÄÈïøÂÖ¨ÂÖ±Â≠êÂ∫èÂàó(LCS)„ÄÇ\n",
    "    ROUGE-Lsum: Âü∫‰∫é LCS ÁöÑ‰∏Ä‰∏™Âèò‰ΩìÔºå‰∏ìÈó®Áî®‰∫éÈïøÊñáÊú¨ÁöÑËØÑ‰º∞„ÄÇ\n",
    "    '''\n",
    "    # ËÆ°ÁÆó ROUGE ÂàÜÊï∞\n",
    "    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    rouge1_mid_f1 = rouge_results['rouge1'][1][2]\n",
    "    rouge2_mid_f1 = rouge_results['rouge2'][1][2]\n",
    "    rougeL_mid_f1 = rouge_results['rougeL'][1][2]\n",
    "    rougeLsum_mid_f1 = rouge_results['rougeLsum'][1][2]\n",
    "    print(f\"ROUGE-1 F1 score: {rouge1_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-2 F1 score: {rouge2_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-L F1 score: {rougeL_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-Lsum F1 score: {rougeLsum_mid_f1:.5f}\")\n",
    "\n",
    "    # ËÆ°ÁÆó METEOR ÂàÜÊï∞\n",
    "    meteor_scores = [meteor_score(references=refs, hypothesis=pred) for pred, refs in zip(predictions_tokenized, references_tokenized)]\n",
    "    average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "    print(f\"Average METEOR score: {average_meteor_score:.5f}\")\n",
    "\n",
    "    # ËÆ°ÁÆó BERTScore ÂàÜÊï∞\n",
    "    '''\n",
    "    ÂêåÊ†∑ÊïàÊûúÔºö\n",
    "    bert_metric = load_metric(\"bertscore\",cache_dir=\"/media/fenghe/New Volume/A2Q/Metric\")\n",
    "    bert_results = bert_metric.compute(predictions=predictions, references=references,lang=\"en\",device=f\"cuda:{torch.cuda.device_count() - 1}\")\n",
    "\n",
    "    ËÆæÁΩÆ verbose=True ‰ºö‰ΩøÂáΩÊï∞Âú®ËÆ°ÁÆóËøáÁ®ã‰∏≠ËæìÂá∫Êõ¥Â§öÁöÑ‰ø°ÊÅØÔºå‰æãÂ¶ÇÂ§ÑÁêÜËøõÂ∫¶„ÄÅÂΩìÂâçÊ≠£Âú®Â§ÑÁêÜÁöÑÊï∞ÊçÆÁ≠â„ÄÇ\n",
    "    '''\n",
    "    P, R, F1 = score(predictions, [ref[0] for ref in references], lang=\"en\", verbose=False)\n",
    "    average_bert_score = F1.mean().item()\n",
    "    print(f\"Average BERTScore F1: {average_bert_score:.5f}\")\n",
    "\n",
    "    return {\n",
    "        \"BLEU\":B_S,\n",
    "        \"ROUGE\":rouge_results,\n",
    "        \"METERO\":meteor_scores,\n",
    "        \"BERTScore\":{\"Precision\":P,\"Recall\":R,\"F1\":F1},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path you save the DI_generation_text:  ablation/GenText/gptrqa/DI_gptrqa_gen_0.2.txt\n"
     ]
    }
   ],
   "source": [
    "print('The path you save the DI_generation_text: ', DI_generation_texts_pth)\n",
    "with open(DI_generation_texts_pth, 'r') as file:\n",
    "    content = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = [ [i.replace('enquiry: ',\"\")] for i in test_dataset_df['target_text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1 score: 0.58431\n",
      "BLEU-2 score: 0.30974\n",
      "BLEU-3 score: 0.19928\n",
      "BLEU-4 score: 0.13850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/RL4LM/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 F1 score: 0.37422\n",
      "ROUGE-2 F1 score: 0.21786\n",
      "ROUGE-L F1 score: 0.34086\n",
      "ROUGE-Lsum F1 score: 0.34090\n",
      "Average METEOR score: 0.27293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BERTScore F1: 0.89038\n"
     ]
    }
   ],
   "source": [
    "res = Calmetic(references=refs,predictions=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.03780876062855267, 'precisions': [0.5843122756383499, 0.3097445526737863, 0.19928375210343885, 0.13850322249655306], 'brevity_penalty': 0.14221562920762718, 'length_ratio': 0.33893584597536675, 'translation_length': 83849, 'reference_length': 247389}\n",
      "Score(precision=np.float64(0.5587394981123432), recall=np.float64(0.27753149912231906), fmeasure=np.float64(0.3409030483913431))\n"
     ]
    }
   ],
   "source": [
    "# ‰∏§‰∏™ÈáçË¶ÅÊï∞ÂÄº\n",
    "print(res['BLEU'])\n",
    "print(res['ROUGE']['rougeLsum'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.7657387256622314\n",
      "Biggest Cosine Similarity: 1.0000007152557373\n",
      "Middle Cosine Similarity: 0.788270890712738\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity as torch_cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')  #SentenceTransformer(\"bert-base-uncased\") \n",
    "\n",
    "reference_texts_ = [ i.replace('enquiry: ',\"\") for i in test_dataset_df['target_text'] ]\n",
    "embeddings1 = sentence_model.encode(content, convert_to_tensor=True)\n",
    "embeddings2 = sentence_model.encode(reference_texts_, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores_2 = util.pytorch_cos_sim(embeddings1, embeddings2)   #[52002,52002]Áª¥Â∫¶ÁöÑÁü©ÈòµÔºåÂØπËßíÁ∫ø‰∏äÁöÑÂÄº‰∏∫ÂØπÂ∫îÊñáÊú¨ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶\n",
    "\n",
    "# ËæìÂá∫‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÁöÑÂÄº\n",
    "print(f\"Average Cosine Similarity: {cosine_scores_2.diagonal().mean()}\")\n",
    "print(f\"Biggest Cosine Similarity: {cosine_scores_2.diagonal().max()}\")\n",
    "print(f\"Middle Cosine Similarity: {cosine_scores_2.diagonal().median()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DI+FTÔºàÈúÄË¶ÅÁî®Âà∞RL4LMÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "train_dataset_t5 = load_from_disk('')\n",
    "val_dataset_t5 = load_from_disk('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(val_dataset_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "def tokenize_t5_function(examples):\n",
    "    model_inputs = t5_tokenizer(examples['input_text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    labels = t5_tokenizer(examples['target_text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "#tokenized_train_dataset_t5 = train_dataset_t5.map(tokenize_t5_function, batched=True)\n",
    "tokenized_val_dataset_t5 = val_dataset_t5.map(tokenize_t5_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DI_FT_t5_base_model = T5ForConditionalGeneration.from_pretrained('/home/fenghe/Ans2Seq/real_world/DI_MED_t5_small_25e').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(answer):\n",
    "    DI_FT_t5_base_model.eval()  # Â∞ÜÊ®°ÂûãËÆæÁΩÆ‰∏∫ËØÑ‰º∞Ê®°Âºè\n",
    "    input_ids = t5_tokenizer.encode(\"answer: \" + answer, return_tensors=\"pt\").to(device)\n",
    "    outputs = DI_FT_t5_base_model.generate(input_ids, num_beams=10,max_length=250,temperature=100,top_k=200)\n",
    "    question = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ëé∑ÂèñÂá†‰∏™Ê†∑Êú¨\n",
    "samples = val_dataset_t5.shuffle(seed=42).select(range(5))  # ÈöèÊú∫ÈÄâÊã©5‰∏™Ê†∑Êú¨\n",
    "\n",
    "# ÁîüÊàêÈóÆÈ¢òÂπ∂ÊØîËæÉ\n",
    "for example in samples:\n",
    "    generated_question = generate_question(example['input_text'].replace(\"answer: \", \"\"))\n",
    "    print(f\"Answer: {example['input_text'].replace('answer: ', '')}\")\n",
    "    print(f\"Generated Question: {generated_question}\")\n",
    "    print(f\"Actual Question: {example['target_text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openworld_responses = [\"Based on your symptoms, it sounds like you may have a fracture in your hand.\",\n",
    "\"It seems like you may have a foreign body stuck in your nose causing those symptoms. We will need to take a look and remove it if necessary.\",\n",
    "\"Based on your symptoms, it's possible that you could have esophageal cancer. Fatigue is a common symptom of this disease. We'll need to run some tests to confirm the diagnosis.\",\n",
    "\"You will need radiographic imaging of your shoulder, including a plain x-ray to see the extent of the injury. We may also need to suture the wound, perform a complete blood count, and provide intravenous fluid replacement. Additionally, we will need to manage wound care and perform kidney function tests to monitor renal function.\",\n",
    "\"Based on your symptoms, you may have a corneal abrasion, which is a scratch on the clear, protective layer on the front of your eye. Have you had anything come in contact with your eye recently?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ëé∑ÂèñÂá†‰∏™Ê†∑Êú¨\n",
    "samples = openworld_responses  # ÈöèÊú∫ÈÄâÊã©5‰∏™Ê†∑Êú¨\n",
    "\n",
    "# ÁîüÊàêÈóÆÈ¢òÂπ∂ÊØîËæÉ\n",
    "for example in samples:\n",
    "    generated_question = generate_question(example)\n",
    "    print(f\"Answer: {example}\")\n",
    "    print(f\"Generated Question: {generated_question}\")\n",
    "    print(f\"Actual Question: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Ëé∑ÂèñÂá†‰∏™Ê†∑Êú¨\n",
    "samples = val_dataset_t5  # ÈöèÊú∫ÈÄâÊã©5‰∏™Ê†∑Êú¨\n",
    "res = []\n",
    "# ÁîüÊàêÈóÆÈ¢òÂπ∂ÊØîËæÉ\n",
    "with open('/home/fenghe/Ans2Seq/real_world/DI_FT_rouge_meddata_gen_0_2_ppo_25e.txt', 'a') as file:\n",
    "    for example in tqdm(samples):\n",
    "        generated_question = generate_question(example['input_text'].replace(\"answer: \", \"\"))\n",
    "        res.append(generated_question.replace(\"enquiry: \", \"\"))\n",
    "        file.write((generated_question.replace(\"enquiry: \", \"\")+'\\n'))\n",
    "        # print(f\"Answer: {example['input_text'].replace('answer: ', '')}\")\n",
    "        # print(f\"Generated Question: {generated_question}\")\n",
    "        # print(f\"Actual Question: {example['target_text']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bert_score import score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def Calmetic(references:list[list[str]], predictions:list[str]):\n",
    "    '''\n",
    "    Input format:\n",
    "\n",
    "    predictions = [\n",
    "        \"What is the capital of France?\",\n",
    "        \"Who wrote the book?\",\n",
    "        \"What is the largest planet?\"\n",
    "    ]\n",
    "\n",
    "    references = [\n",
    "        [\"What is the capital city of France?\"],\n",
    "        [\"Who is the author of the book?\"],\n",
    "        [\"Which planet is the largest in the solar system?\"]\n",
    "    ]\n",
    "    '''\n",
    "\n",
    "    # # Âä†ËΩΩ BLEU ËØÑÂàÜÂô®\n",
    "    # bleu_metric = load_metric(\"bleu\")\n",
    "\n",
    "    # # ËÆ°ÁÆó BLEU ÂàÜÊï∞\n",
    "    predictions_tokenized = [word_tokenize(pred) for pred in predictions]\n",
    "    references_tokenized = [[word_tokenize(refs[0])] for refs in references]\n",
    "    # B_S = {}\n",
    "    # for n in range(1, 5):\n",
    "    #     bleu_metric.add_batch(predictions=predictions_tokenized, references=references_tokenized)\n",
    "    #     results = bleu_metric.compute(max_order=n)\n",
    "    #     B_S[f\"BLEU-{n}\"] = results\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    B_S = bleu_metric.compute(predictions=predictions, references=references,tokenizer=word_tokenize)\n",
    "    for i,n in enumerate(B_S['precisions']):\n",
    "        print(f\"BLEU-{i+1} score: {n:.5f}\")\n",
    "        \n",
    "\n",
    "\n",
    "    # Âä†ËΩΩ ROUGE ËØÑÂàÜÂô®\n",
    "    rouge_metric = load_metric(\"rouge\")\n",
    "    '''\n",
    "    ROUGE-1: Ë°°ÈáèÁîüÊàêÊñáÊú¨ÂíåÂèÇËÄÉÊñáÊú¨‰πãÈó¥ÁöÑ unigram ÂåπÈÖç„ÄÇ\n",
    "    ROUGE-2: Ë°°ÈáèÁîüÊàêÊñáÊú¨ÂíåÂèÇËÄÉÊñáÊú¨‰πãÈó¥ÁöÑ bigram ÂåπÈÖç„ÄÇ\n",
    "    ROUGE-L: Ë°°ÈáèÁîüÊàêÊñáÊú¨ÂíåÂèÇËÄÉÊñáÊú¨‰πãÈó¥ÁöÑÊúÄÈïøÂÖ¨ÂÖ±Â≠êÂ∫èÂàó(LCS)„ÄÇ\n",
    "    ROUGE-Lsum: Âü∫‰∫é LCS ÁöÑ‰∏Ä‰∏™Âèò‰ΩìÔºå‰∏ìÈó®Áî®‰∫éÈïøÊñáÊú¨ÁöÑËØÑ‰º∞„ÄÇ\n",
    "    '''\n",
    "    # ËÆ°ÁÆó ROUGE ÂàÜÊï∞\n",
    "    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    rouge1_mid_f1 = rouge_results['rouge1'][1][2]\n",
    "    rouge2_mid_f1 = rouge_results['rouge2'][1][2]\n",
    "    rougeL_mid_f1 = rouge_results['rougeL'][1][2]\n",
    "    rougeLsum_mid_f1 = rouge_results['rougeLsum'][1][2]\n",
    "    print(f\"ROUGE-1 F1 score: {rouge1_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-2 F1 score: {rouge2_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-L F1 score: {rougeL_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-Lsum F1 score: {rougeLsum_mid_f1:.5f}\")\n",
    "\n",
    "    # ËÆ°ÁÆó METEOR ÂàÜÊï∞\n",
    "    meteor_scores = [meteor_score(references=refs, hypothesis=pred) for pred, refs in zip(predictions_tokenized, references_tokenized)]\n",
    "    average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "    print(f\"Average METEOR score: {average_meteor_score:.5f}\")\n",
    "\n",
    "    # ËÆ°ÁÆó BERTScore ÂàÜÊï∞\n",
    "    '''\n",
    "    ÂêåÊ†∑ÊïàÊûúÔºö\n",
    "    bert_metric = load_metric(\"bertscore\",cache_dir=\"/media/fenghe/New Volume/A2Q/Metric\")\n",
    "    bert_results = bert_metric.compute(predictions=predictions, references=references,lang=\"en\",device=f\"cuda:{torch.cuda.device_count() - 1}\")\n",
    "\n",
    "    ËÆæÁΩÆ verbose=True ‰ºö‰ΩøÂáΩÊï∞Âú®ËÆ°ÁÆóËøáÁ®ã‰∏≠ËæìÂá∫Êõ¥Â§öÁöÑ‰ø°ÊÅØÔºå‰æãÂ¶ÇÂ§ÑÁêÜËøõÂ∫¶„ÄÅÂΩìÂâçÊ≠£Âú®Â§ÑÁêÜÁöÑÊï∞ÊçÆÁ≠â„ÄÇ\n",
    "    '''\n",
    "    P, R, F1 = score(predictions, [ref[0] for ref in references], lang=\"en\", verbose=False)\n",
    "    average_bert_score = F1.mean().item()\n",
    "    print(f\"Average BERTScore F1: {average_bert_score:.5f}\")\n",
    "\n",
    "    return {\n",
    "        \"BLEU\":B_S,\n",
    "        \"ROUGE\":rouge_results,\n",
    "        \"METERO\":meteor_scores,\n",
    "        \"BERTScore\":{\"Precision\":P,\"Recall\":R,\"F1\":F1},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/fenghe/Ans2Seq/real_world/DI_FT_rouge_meddata_gen_0_2_ppo_25e.txt', 'r') as file:\n",
    "    content = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = [ [i.replace('enquiry: ',\"\")] for i in val_dataset_t5['target_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Calmetic(references=refs,predictions=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res['BLEU']['precisions'])\n",
    "print(res['ROUGE']['rougeL'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity as torch_cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')#SentenceTransformer(\"bert-base-uncased\") \n",
    "\n",
    "reference_texts_ = [ i.replace('enquiry: ',\"\") for i in val_dataset_t5['target_text'] ]\n",
    "embeddings1 = sentence_model.encode(content, convert_to_tensor=True)\n",
    "embeddings2 = sentence_model.encode(reference_texts_, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores_2 = util.pytorch_cos_sim(embeddings1, embeddings2)   #[52002,52002]Áª¥Â∫¶ÁöÑÁü©ÈòµÔºåÂØπËßíÁ∫ø‰∏äÁöÑÂÄº‰∏∫ÂØπÂ∫îÊñáÊú¨ÁöÑ‰ΩôÂº¶Áõ∏‰ººÂ∫¶\n",
    "\n",
    "# ËæìÂá∫‰ΩôÂº¶Áõ∏‰ººÂ∫¶ÁöÑÂÄº\n",
    "print(f\"Average Cosine Similarity: {cosine_scores_2.diagonal().mean()}\")\n",
    "print(f\"Biggest Cosine Similarity: {cosine_scores_2.diagonal().max()}\")\n",
    "print(f\"Middle Cosine Similarity: {cosine_scores_2.diagonal().median()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_lst = []\n",
    "for idx,num in enumerate(cosine_scores_2.diagonal()):\n",
    "    if num>=0.9:\n",
    "        index_lst.append(idx)\n",
    "\n",
    "print(len(index_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_lst = [27, 34, 61, 67, 101, 113, 117, 128, 141, 163, 189, 200, 210, 243, 245, 253, 264, 283, 313, 325, 326, 329, 359, 365, 374, 376, 385, 387, 392, 394, 418, 425, 478, 482, 502, 504, 508, 511, 515, 571, 580, 583, 589, 598, 618, 641, 667, 677, 698, 711, 713, 753, 754, 779, 799, 800, 827, 830, 835, 862, 884, 908, 909, 914, 961, 970, 984, 992, 1008, 1017, 1021, 1030, 1032, 1033]\n",
    "print(index_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[content[i] for i in index_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame(val_dataset_t5).iloc[index_lst][['input','output']]\n",
    "_df['generate'] = [content[i] for i in index_lst]\n",
    "_df['index'] = index_lst\n",
    "_df.to_csv('real_world/csover0-9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 385\n",
    "print(pd.DataFrame(val_dataset_t5).iloc[n]['input'])\n",
    "print(content[n])\n",
    "print(pd.DataFrame(val_dataset_t5).iloc[n]['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Based on your symptoms, it sounds like you may have a fracture in your hand.' in train_dataset_t5['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 113 618 511 571 992# 329 365 385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_dataset_df.iloc[1592]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('real_world/csover0-9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL4LM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
