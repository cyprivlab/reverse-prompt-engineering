{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670f917c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer,T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "rl_model=T5ForConditionalGeneration.from_pretrained('./DI_FT_Alpaca_modifyBLEU/30e/model')\n",
    "rl_model.to(device)\n",
    "rl_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8225b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_one_text(u_model,one_text):\n",
    "    inputs = tokenizer(one_text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = u_model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=50,\n",
    "        early_stopping=True)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9ada8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 9000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./result_claude_haiku.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "original_prompts = [item['instruction'] for item in data]\n",
    "\n",
    "# average_len=0\n",
    "# for i in range(len(original_prompts)):\n",
    "#     average_len=average_len+len(original_prompts[i])\n",
    "# print(average_len/len(original_prompts))\n",
    "\n",
    "claude_prompts=[item['output'] for item in data]\n",
    "print(len(original_prompts),len(claude_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0cccfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9000 [00:00<?, ?it/s]/home/fenghe/anaconda3/envs/RL4LM/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:649: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "  0%|          | 5/9000 [00:00<17:34,  8.53it/s]  Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 9000/9000 [18:34<00:00,  8.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "rl_generated_caption=[]\n",
    "\n",
    "len_generation=len(claude_prompts)\n",
    "for i in tqdm(range(len_generation)):\n",
    "    rl_generated_caption.append(optimize_one_text(rl_model,claude_prompts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aa75502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reference_caption",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generated_caption",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c30f9174-de11-422f-94fe-32ab228b48cb",
       "rows": [
        [
         "0",
         "Give three tips for staying healthy.",
         "enquiry: Write three tips for staying healthy."
        ],
        [
         "1",
         "Give three tips for staying healthy.",
         "enquiry: Generate three tips for staying healthy."
        ],
        [
         "2",
         "Give three tips for staying healthy.",
         "enquiry: Write 3 tips for staying healthy."
        ],
        [
         "3",
         "What are the three primary colors?",
         "enquiry: List the three primary colors."
        ],
        [
         "4",
         "What are the three primary colors?",
         "enquiry: What are the three primary colors?"
        ],
        [
         "5",
         "What are the three primary colors?",
         "enquiry: List the three primary colors."
        ],
        [
         "6",
         "Describe the structure of an atom.",
         "enquiry: Describe the structure of an atom."
        ],
        [
         "7",
         "Describe the structure of an atom.",
         "enquiry: Describe the basic structure of an atom."
        ],
        [
         "8",
         "Describe the structure of an atom.",
         "enquiry: Describe the structure of an atom."
        ],
        [
         "9",
         "How can we reduce air pollution?",
         "enquiry: How can we reduce air pollution?"
        ],
        [
         "10",
         "How can we reduce air pollution?",
         "enquiry: Suggest some effective ways to reduce air pollution."
        ],
        [
         "11",
         "How can we reduce air pollution?",
         "enquiry: Suggest some effective ways to reduce air pollution."
        ],
        [
         "12",
         "Describe a time when you had to make a difficult decision.",
         "enquiry: Describe your experience making a difficult decision."
        ],
        [
         "13",
         "Describe a time when you had to make a difficult decision.",
         "enquiry: Explain the type of difficult decision that you might face."
        ],
        [
         "14",
         "Describe a time when you had to make a difficult decision.",
         "enquiry: Describe your experience with a difficult decision making process."
        ],
        [
         "15",
         "Identify the odd one out.",
         "enquiry: Find the odd one out in the list Twitter, Instagram, Telegram"
        ],
        [
         "16",
         "Identify the odd one out.",
         "enquiry: Find the odd one out in the given list Twitter, Instagram, Telegram"
        ],
        [
         "17",
         "Identify the odd one out.",
         "enquiry: Find the odd one out in the given list Twitter, Instagram, Twitter"
        ],
        [
         "18",
         "Explain why the following fraction is equivalent to 1/4",
         "enquiry: Explain why the following fraction is equivalent to 1/4 4/16"
        ],
        [
         "19",
         "Explain why the following fraction is equivalent to 1/4",
         "enquiry: Explain why the following fraction is equivalent to 1/4 4/16"
        ],
        [
         "20",
         "Explain why the following fraction is equivalent to 1/4",
         "enquiry: Explain why the following fraction is equivalent to 1/4 4/16"
        ],
        [
         "21",
         "Write a short story in third person narration about a protagonist who has to make an important career decision.",
         "enquiry: Write a short story in third person narration about a protagonist who has to make an important career decision."
        ],
        [
         "22",
         "Write a short story in third person narration about a protagonist who has to make an important career decision.",
         "enquiry: Write a short story in third person narration about a protagonist who has to make an important career decision."
        ],
        [
         "23",
         "Write a short story in third person narration about a protagonist who has to make an important career decision.",
         "enquiry: Write a short story in third person narration about a protagonist who has to make an important career decision."
        ],
        [
         "24",
         "Render a 3D model of a house",
         "enquiry: Reverse engineer a house in a 3D model."
        ],
        [
         "25",
         "Render a 3D model of a house",
         "enquiry: Create a 3D model of a house."
        ],
        [
         "26",
         "Render a 3D model of a house",
         "enquiry: Create a 3D model of a house."
        ],
        [
         "27",
         "Evaluate this sentence for spelling and grammar mistakes",
         "enquiry: Analyze the following sentence for spelling and grammar mistakes He finnished his meal and left the resturant."
        ],
        [
         "28",
         "Evaluate this sentence for spelling and grammar mistakes",
         "enquiry: Analyze the sentence for spelling and grammar mistakes He finnished his meal and left the resturant"
        ],
        [
         "29",
         "Evaluate this sentence for spelling and grammar mistakes",
         "enquiry: Analyze the following sentence for spelling and grammar mistakes He finnished his meal and left the resturant."
        ],
        [
         "30",
         "How did Julius Caesar die?",
         "enquiry: Find key details about Julius Caesar's death."
        ],
        [
         "31",
         "How did Julius Caesar die?",
         "enquiry: Summarize the historical events surrounding the given event. Julius Caesar assassinated by a group of Roman senators"
        ],
        [
         "32",
         "How did Julius Caesar die?",
         "enquiry: Describe the key details of Julius Caesar's assassination."
        ],
        [
         "33",
         "What is the capital of France?",
         "enquiry: What is the capital of France?"
        ],
        [
         "34",
         "What is the capital of France?",
         "enquiry: What is the capital of France?"
        ],
        [
         "35",
         "What is the capital of France?",
         "enquiry: What is the capital of France?"
        ],
        [
         "36",
         "Generate a list of ten items a person might need for a camping trip",
         "enquiry: Make a list of 10 items a person might need for a camping trip."
        ],
        [
         "37",
         "Generate a list of ten items a person might need for a camping trip",
         "enquiry: Generate a list of 10 items a person might need for a camping trip."
        ],
        [
         "38",
         "Generate a list of ten items a person might need for a camping trip",
         "enquiry: Make a list of 10 items a person might need for a camping trip."
        ],
        [
         "39",
         "Discuss the causes of the Great Depression",
         "enquiry: Describe the factors that led to the Great Depression in the 1930s."
        ],
        [
         "40",
         "Discuss the causes of the Great Depression",
         "enquiry: Explain the causes of the Great Depression."
        ],
        [
         "41",
         "Discuss the causes of the Great Depression",
         "enquiry: Explain why the Great Depression caused the world to a certain event."
        ],
        [
         "42",
         "Classify the following into animals, plants, and minerals",
         "enquiry: Classify the following items: Oak tree, Copper ore, Elephant"
        ],
        [
         "43",
         "Classify the following into animals, plants, and minerals",
         "enquiry: Classify the following items: animals, plants, and minerals. Oak tree, Copper ore"
        ],
        [
         "44",
         "Classify the following into animals, plants, and minerals",
         "enquiry: Classify the following items: animals, plants, elephant, copper ore."
        ],
        [
         "45",
         "Explain the use of word embeddings in Natural Language Processing",
         "enquiry: Describe the benefits of using word embeddings in natural language processing."
        ],
        [
         "46",
         "Explain the use of word embeddings in Natural Language Processing",
         "enquiry: Explain the uses and benefits of using word embeddings in natural language processing."
        ],
        [
         "47",
         "Explain the use of word embeddings in Natural Language Processing",
         "enquiry: Explain the purpose of word embeddings in Natural Language Processing (NLP)."
        ],
        [
         "48",
         "Describe the function of a computer motherboard",
         "enquiry: Describe the primary functions of a computer motherboard."
        ],
        [
         "49",
         "Describe the function of a computer motherboard",
         "enquiry: Describe the primary functions of a computer motherboard."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_caption</th>\n",
       "      <th>generated_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td>enquiry: Write three tips for staying healthy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td>enquiry: Generate three tips for staying healthy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td>enquiry: Write 3 tips for staying healthy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the three primary colors?</td>\n",
       "      <td>enquiry: List the three primary colors.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the three primary colors?</td>\n",
       "      <td>enquiry: What are the three primary colors?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>Name a job that requires a lot of physical str...</td>\n",
       "      <td>enquiry: What types of jobs typically require ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>Name a job that requires a lot of physical str...</td>\n",
       "      <td>enquiry: Provide examples of jobs that require...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>Tell me a riddle.</td>\n",
       "      <td>enquiry: Create a riddle that follows the give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>Tell me a riddle.</td>\n",
       "      <td>enquiry: Create a riddle that follows the give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>Tell me a riddle.</td>\n",
       "      <td>enquiry: Create a riddle for the following sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      reference_caption  \\\n",
       "0                  Give three tips for staying healthy.   \n",
       "1                  Give three tips for staying healthy.   \n",
       "2                  Give three tips for staying healthy.   \n",
       "3                    What are the three primary colors?   \n",
       "4                    What are the three primary colors?   \n",
       "...                                                 ...   \n",
       "8995  Name a job that requires a lot of physical str...   \n",
       "8996  Name a job that requires a lot of physical str...   \n",
       "8997                                  Tell me a riddle.   \n",
       "8998                                  Tell me a riddle.   \n",
       "8999                                  Tell me a riddle.   \n",
       "\n",
       "                                      generated_caption  \n",
       "0        enquiry: Write three tips for staying healthy.  \n",
       "1     enquiry: Generate three tips for staying healthy.  \n",
       "2            enquiry: Write 3 tips for staying healthy.  \n",
       "3               enquiry: List the three primary colors.  \n",
       "4           enquiry: What are the three primary colors?  \n",
       "...                                                 ...  \n",
       "8995  enquiry: What types of jobs typically require ...  \n",
       "8996  enquiry: Provide examples of jobs that require...  \n",
       "8997  enquiry: Create a riddle that follows the give...  \n",
       "8998  enquiry: Create a riddle that follows the give...  \n",
       "8999  enquiry: Create a riddle for the following sen...  \n",
       "\n",
       "[9000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "compare_promts={\n",
    "    'reference_caption': original_prompts,\n",
    "    'generated_caption': rl_generated_caption,\n",
    "}\n",
    "compare_promts = pd.DataFrame(compare_promts)\n",
    "compare_promts\n",
    "# compare_promts.to_parquet(f'./rl_other_generative_model_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "696b0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bert_score import score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def Calmetic(references:list[list[str]], predictions:list[str]):\n",
    "    '''\n",
    "    Input format:\n",
    "\n",
    "    predictions = [\n",
    "        \"What is the capital of France?\",\n",
    "        \"Who wrote the book?\",\n",
    "        \"What is the largest planet?\"\n",
    "    ]\n",
    "\n",
    "    references = [\n",
    "        [\"What is the capital city of France?\"],\n",
    "        [\"Who is the author of the book?\"],\n",
    "        [\"Which planet is the largest in the solar system?\"]\n",
    "    ]\n",
    "    '''\n",
    "\n",
    "    # # 加载 BLEU 评分器\n",
    "    # bleu_metric = load_metric(\"bleu\")\n",
    "\n",
    "    # # 计算 BLEU 分数\n",
    "    predictions_tokenized = [word_tokenize(pred) for pred in predictions]\n",
    "    references_tokenized = [[word_tokenize(refs[0])] for refs in references]\n",
    "    # B_S = {}\n",
    "    # for n in range(1, 5):\n",
    "    #     bleu_metric.add_batch(predictions=predictions_tokenized, references=references_tokenized)\n",
    "    #     results = bleu_metric.compute(max_order=n)\n",
    "    #     B_S[f\"BLEU-{n}\"] = results\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    B_S = bleu_metric.compute(predictions=predictions, references=references,tokenizer=word_tokenize)\n",
    "    for i,n in enumerate(B_S['precisions']):\n",
    "        print(f\"BLEU-{i+1} score: {n:.5f}\")\n",
    "        \n",
    "\n",
    "\n",
    "    # 加载 ROUGE 评分器\n",
    "    rouge_metric = load_metric(\"rouge\")\n",
    "    '''\n",
    "    ROUGE-1: 衡量生成文本和参考文本之间的 unigram 匹配。\n",
    "    ROUGE-2: 衡量生成文本和参考文本之间的 bigram 匹配。\n",
    "    ROUGE-L: 衡量生成文本和参考文本之间的最长公共子序列(LCS)。\n",
    "    ROUGE-Lsum: 基于 LCS 的一个变体，专门用于长文本的评估。\n",
    "    '''\n",
    "    # 计算 ROUGE 分数\n",
    "    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    rouge1_mid_f1 = rouge_results['rouge1'][1][2]\n",
    "    rouge2_mid_f1 = rouge_results['rouge2'][1][2]\n",
    "    rougeL_mid_f1 = rouge_results['rougeL'][1][2]\n",
    "    rougeLsum_mid_f1 = rouge_results['rougeLsum'][1][2]\n",
    "    print(f\"ROUGE-1 F1 score: {rouge1_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-2 F1 score: {rouge2_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-L F1 score: {rougeL_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-Lsum F1 score: {rougeLsum_mid_f1:.5f}\")\n",
    "\n",
    "    # 计算 METEOR 分数\n",
    "    meteor_scores = [meteor_score(references=refs, hypothesis=pred) for pred, refs in zip(predictions_tokenized, references_tokenized)]\n",
    "    average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "    print(f\"Average METEOR score: {average_meteor_score:.5f}\")\n",
    "\n",
    "    # 计算 BERTScore 分数\n",
    "    '''\n",
    "    同样效果：\n",
    "    bert_metric = load_metric(\"bertscore\",cache_dir=\"/media/fenghe/New Volume/A2Q/Metric\")\n",
    "    bert_results = bert_metric.compute(predictions=predictions, references=references,lang=\"en\",device=f\"cuda:{torch.cuda.device_count() - 1}\")\n",
    "\n",
    "    设置 verbose=True 会使函数在计算过程中输出更多的信息，例如处理进度、当前正在处理的数据等。\n",
    "    '''\n",
    "    P, R, F1 = score(predictions, [ref[0] for ref in references], lang=\"en\", verbose=False)\n",
    "    average_bert_score = F1.mean().item()\n",
    "    print(f\"Average BERTScore F1: {average_bert_score:.5f}\")\n",
    "\n",
    "    return {\n",
    "        \"BLEU\":B_S,\n",
    "        \"ROUGE\":rouge_results,\n",
    "        \"METERO\":meteor_scores,\n",
    "        \"BERTScore\":{\"Precision\":P,\"Recall\":R,\"F1\":F1},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81b2a9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1 score: 0.40871\n",
      "BLEU-2 score: 0.28403\n",
      "BLEU-3 score: 0.22146\n",
      "BLEU-4 score: 0.17463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenghe/anaconda3/envs/RL4LM/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 F1 score: 0.56393\n",
      "ROUGE-2 F1 score: 0.42253\n",
      "ROUGE-L F1 score: 0.54331\n",
      "ROUGE-Lsum F1 score: 0.54361\n",
      "Average METEOR score: 0.00341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BERTScore F1: 0.81366\n"
     ]
    }
   ],
   "source": [
    "res = Calmetic(references=original_prompts,predictions=rl_generated_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f96f887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.2588499938289279, 'precisions': [0.40871474848174555, 0.2840296150454275, 0.22145734536739584, 0.17462990247667157], 'brevity_penalty': 1.0, 'length_ratio': 1.640070978167876, 'translation_length': 155277, 'reference_length': 94677}\n",
      "Score(precision=np.float64(0.49265447647976646), recall=np.float64(0.6506093448006257), fmeasure=np.float64(0.5436050149995293))\n"
     ]
    }
   ],
   "source": [
    "# 两个重要数值\n",
    "print(res['BLEU'])\n",
    "print(res['ROUGE']['rougeLsum'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30adc354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.7393010854721069\n",
      "Biggest Cosine Similarity: 1.0000007152557373\n",
      "Middle Cosine Similarity: 0.8318278789520264\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity as torch_cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')  #SentenceTransformer(\"bert-base-uncased\") \n",
    "\n",
    "reference_texts_ = [ i.replace('enquiry: ',\"\") for i in rl_generated_caption ]\n",
    "embeddings1 = sentence_model.encode(original_prompts, convert_to_tensor=True)\n",
    "embeddings2 = sentence_model.encode(reference_texts_, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores_2 = util.pytorch_cos_sim(embeddings1, embeddings2)   #[52002,52002]维度的矩阵，对角线上的值为对应文本的余弦相似度\n",
    "\n",
    "# 输出余弦相似度的值\n",
    "print(f\"Average Cosine Similarity: {cosine_scores_2.diagonal().mean()}\")\n",
    "print(f\"Biggest Cosine Similarity: {cosine_scores_2.diagonal().max()}\")\n",
    "print(f\"Middle Cosine Similarity: {cosine_scores_2.diagonal().median()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL4LM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
