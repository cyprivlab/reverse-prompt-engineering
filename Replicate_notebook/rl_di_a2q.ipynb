{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer,T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "rl_model=T5ForConditionalGeneration.from_pretrained('./DI_FT_Alpaca_modifyBLEU/30e/model')\n",
    "rl_model.to(device)\n",
    "rl_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8225b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_one_text(u_model,one_text):\n",
    "    inputs = tokenizer(one_text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = u_model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_length=50,\n",
    "        early_stopping=True)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ada8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./result_claude_haiku.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "original_prompts = [item['instruction'] for item in data]\n",
    "\n",
    "# average_len=0\n",
    "# for i in range(len(original_prompts)):\n",
    "#     average_len=average_len+len(original_prompts[i])\n",
    "# print(average_len/len(original_prompts))\n",
    "\n",
    "claude_prompts=[item['output'] for item in data]\n",
    "print(len(original_prompts),len(claude_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cccfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "rl_generated_caption=[]\n",
    "\n",
    "len_generation=len(claude_prompts)\n",
    "for i in tqdm(range(len_generation)):\n",
    "    rl_generated_caption.append(optimize_one_text(rl_model,claude_prompts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa75502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "compare_promts={\n",
    "    'reference_caption': original_prompts,\n",
    "    'generated_caption': rl_generated_caption,\n",
    "}\n",
    "compare_promts = pd.DataFrame(compare_promts)\n",
    "compare_promts\n",
    "# compare_promts.to_parquet(f'./rl_other_generative_model_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "696b0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bert_score import score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def Calmetic(references:list[list[str]], predictions:list[str]):\n",
    "    '''\n",
    "    Input format:\n",
    "\n",
    "    predictions = [\n",
    "        \"What is the capital of France?\",\n",
    "        \"Who wrote the book?\",\n",
    "        \"What is the largest planet?\"\n",
    "    ]\n",
    "\n",
    "    references = [\n",
    "        [\"What is the capital city of France?\"],\n",
    "        [\"Who is the author of the book?\"],\n",
    "        [\"Which planet is the largest in the solar system?\"]\n",
    "    ]\n",
    "    '''\n",
    "\n",
    "    # # 加载 BLEU 评分器\n",
    "    # bleu_metric = load_metric(\"bleu\")\n",
    "\n",
    "    # # 计算 BLEU 分数\n",
    "    predictions_tokenized = [word_tokenize(pred) for pred in predictions]\n",
    "    references_tokenized = [[word_tokenize(refs[0])] for refs in references]\n",
    "    # B_S = {}\n",
    "    # for n in range(1, 5):\n",
    "    #     bleu_metric.add_batch(predictions=predictions_tokenized, references=references_tokenized)\n",
    "    #     results = bleu_metric.compute(max_order=n)\n",
    "    #     B_S[f\"BLEU-{n}\"] = results\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    B_S = bleu_metric.compute(predictions=predictions, references=references,tokenizer=word_tokenize)\n",
    "    for i,n in enumerate(B_S['precisions']):\n",
    "        print(f\"BLEU-{i+1} score: {n:.5f}\")\n",
    "        \n",
    "\n",
    "\n",
    "    # 加载 ROUGE 评分器\n",
    "    rouge_metric = load_metric(\"rouge\")\n",
    "    '''\n",
    "    ROUGE-1: 衡量生成文本和参考文本之间的 unigram 匹配。\n",
    "    ROUGE-2: 衡量生成文本和参考文本之间的 bigram 匹配。\n",
    "    ROUGE-L: 衡量生成文本和参考文本之间的最长公共子序列(LCS)。\n",
    "    ROUGE-Lsum: 基于 LCS 的一个变体，专门用于长文本的评估。\n",
    "    '''\n",
    "    # 计算 ROUGE 分数\n",
    "    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    rouge1_mid_f1 = rouge_results['rouge1'][1][2]\n",
    "    rouge2_mid_f1 = rouge_results['rouge2'][1][2]\n",
    "    rougeL_mid_f1 = rouge_results['rougeL'][1][2]\n",
    "    rougeLsum_mid_f1 = rouge_results['rougeLsum'][1][2]\n",
    "    print(f\"ROUGE-1 F1 score: {rouge1_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-2 F1 score: {rouge2_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-L F1 score: {rougeL_mid_f1:.5f}\")\n",
    "    print(f\"ROUGE-Lsum F1 score: {rougeLsum_mid_f1:.5f}\")\n",
    "\n",
    "    # 计算 METEOR 分数\n",
    "    meteor_scores = [meteor_score(references=refs, hypothesis=pred) for pred, refs in zip(predictions_tokenized, references_tokenized)]\n",
    "    average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "    print(f\"Average METEOR score: {average_meteor_score:.5f}\")\n",
    "\n",
    "    # 计算 BERTScore 分数\n",
    "\n",
    "    P, R, F1 = score(predictions, [ref[0] for ref in references], lang=\"en\", verbose=False)\n",
    "    average_bert_score = F1.mean().item()\n",
    "    print(f\"Average BERTScore F1: {average_bert_score:.5f}\")\n",
    "\n",
    "    return {\n",
    "        \"BLEU\":B_S,\n",
    "        \"ROUGE\":rouge_results,\n",
    "        \"METERO\":meteor_scores,\n",
    "        \"BERTScore\":{\"Precision\":P,\"Recall\":R,\"F1\":F1},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Calmetic(references=original_prompts,predictions=rl_generated_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两个重要数值\n",
    "print(res['BLEU'])\n",
    "print(res['ROUGE']['rougeLsum'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30adc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity as torch_cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')  #SentenceTransformer(\"bert-base-uncased\") \n",
    "\n",
    "reference_texts_ = [ i.replace('enquiry: ',\"\") for i in rl_generated_caption ]\n",
    "embeddings1 = sentence_model.encode(original_prompts, convert_to_tensor=True)\n",
    "embeddings2 = sentence_model.encode(reference_texts_, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores_2 = util.pytorch_cos_sim(embeddings1, embeddings2)   #[52002,52002]维度的矩阵，对角线上的值为对应文本的余弦相似度\n",
    "\n",
    "# 输出余弦相似度的值\n",
    "print(f\"Average Cosine Similarity: {cosine_scores_2.diagonal().mean()}\")\n",
    "print(f\"Biggest Cosine Similarity: {cosine_scores_2.diagonal().max()}\")\n",
    "print(f\"Middle Cosine Similarity: {cosine_scores_2.diagonal().median()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL4LM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
